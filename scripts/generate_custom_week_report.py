"""íŠ¹ì • ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (ë‚ ì§œ ì§€ì •)"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.bigquery.client import BigQueryClient
from src.bigquery.queries import WeeklyDataQuery
from src.classifier.vector_classifier import VectorContentClassifier
from src.storage.data_store import ClassifiedDataStore
from src.vectorstore.chroma_store import ChromaVectorStore
from src.reporter.analytics import WeeklyAnalytics
from src.reporter.report_generator import ReportGenerator
from src.integrations.notion_client import NotionReportClient
from src.integrations.slack_client import SlackNotifier
from src.utils.excel_exporter import export_to_excel


def generate_week_data(start_date, end_date, data_store, master_info=None):
    """íŠ¹ì • ì£¼ê°„ì˜ ë°ì´í„° ìƒì„±"""
    print(f"\n{'='*60}")
    print(f"ğŸ“… {start_date} ~ {end_date} ë°ì´í„° ìƒì„±")
    print('='*60)

    if data_store.exists(start_date):
        print("âœ“ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„° - ê±´ë„ˆëœ€")
        data = data_store.load_weekly_data(start_date)
        return data['letters'], data['posts']

    print("BigQuery ì¡°íšŒ ì¤‘...")
    client = BigQueryClient()
    query = WeeklyDataQuery(client)

    # ë§ˆìŠ¤í„° ì •ë³´ ì¡°íšŒ (í•œ ë²ˆë§Œ)
    if master_info is None:
        print("ë§ˆìŠ¤í„° ì •ë³´ ì¡°íšŒ ì¤‘...")
        master_info = query.get_master_info()
        print(f"âœ“ {len(master_info)}ê°œ ë§ˆìŠ¤í„° ì •ë³´ ë¡œë“œ")

    weekly_data = query.get_weekly_data(start_date, end_date)

    letters = weekly_data['letters']
    posts = weekly_data['posts']
    print(f"âœ“ í¸ì§€ {len(letters)}ê±´, ê²Œì‹œê¸€ {len(posts)}ê±´ ì¡°íšŒ")

    if not letters and not posts:
        print("âŒ ë°ì´í„° ì—†ìŒ")
        return [], []

    # ë§ˆìŠ¤í„° ì´ë¦„ ì¶”ê°€ ë° ì‹¤ì œ masterId ì„¤ì •
    for item in letters:
        master_id = item.get('masterId')
        if master_id and master_id in master_info:
            item['masterName'] = master_info[master_id]['displayName']
            item['masterClubName'] = master_info[master_id]['clubName']
            item['actualMasterId'] = master_id
        else:
            item['masterName'] = 'Unknown'
            item['masterClubName'] = 'Unknown'
            item['actualMasterId'] = master_id or 'unknown'

    # ê²Œì‹œê¸€: postBoardIdë¥¼ ì‹¤ì œ masterIdë¡œ ë³€í™˜
    client_for_boards = BigQueryClient()
    board_to_master_query = f"""
    SELECT _id as boardId, masterId
    FROM `{client_for_boards.project_id}.us_plus.postboards`
    """
    board_to_master = {b['boardId']: b['masterId']
                       for b in client_for_boards.execute_query(board_to_master_query)}

    for item in posts:
        board_id = item.get('postBoardId')
        # postBoardIdë¥¼ ì‹¤ì œ masterIdë¡œ ë³€í™˜
        actual_master_id = board_to_master.get(board_id, board_id)

        if actual_master_id and actual_master_id in master_info:
            item['masterName'] = master_info[actual_master_id]['displayName']
            item['masterClubName'] = master_info[actual_master_id]['clubName']
            item['actualMasterId'] = actual_master_id
        else:
            item['masterName'] = 'Unknown'
            item['masterClubName'] = 'Unknown'
            item['actualMasterId'] = actual_master_id or 'unknown'

    print("ë¶„ë¥˜ ì¤‘...")
    classifier = VectorContentClassifier()
    classified_letters = classifier.classify_batch(letters, "message") if letters else []
    classified_posts = classifier.classify_batch(posts, "textBody") if posts else []

    print("ì €ì¥ ì¤‘...")
    data_store.save_weekly_data(start_date, end_date, classified_letters, classified_posts)
    print(f"âœ“ ì €ì¥ ì™„ë£Œ: {start_date}.json")

    return classified_letters, classified_posts


def main():
    # ëŒ€ìƒ ì£¼ê°„ (12ì›” 29ì¼ ~ 1ì›” 4ì¼)
    target_start = "2025-12-29"
    target_end = "2026-01-05"  # 1-4 ë‹¤ìŒë‚ ê¹Œì§€ (exclusive)

    # ì „ì£¼ (12ì›” 22ì¼ ~ 12ì›” 28ì¼)
    prev_start = "2025-12-22"
    prev_end = "2025-12-29"

    print("="*60)
    print("ğŸ“Š íŠ¹ì • ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±")
    print("="*60)

    data_store = ClassifiedDataStore()

    # 1. ì „ì£¼ ë°ì´í„° ìƒì„±
    print("\n[1ë‹¨ê³„] ì „ì£¼ ë°ì´í„° ìƒì„±")
    prev_letters, prev_posts = generate_week_data(prev_start, prev_end, data_store)

    # 2. ëŒ€ìƒ ì£¼ê°„ ë°ì´í„° ìƒì„±
    print("\n[2ë‹¨ê³„] ëŒ€ìƒ ì£¼ê°„ ë°ì´í„° ìƒì„±")
    classified_letters, classified_posts = generate_week_data(target_start, target_end, data_store)

    if not classified_letters and not classified_posts:
        print("\nâŒ ëŒ€ìƒ ì£¼ê°„ ë°ì´í„°ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
    print(f"\n[3ë‹¨ê³„] ë²¡í„° ìŠ¤í† ì–´ ì €ì¥")
    try:
        store = ChromaVectorStore(
            collection_name=f"week_{target_start}",
            persist_directory="./chroma_db"
        )
        store.reset()

        total_added = 0
        if classified_letters:
            for letter in classified_letters:
                letter["message"] = letter.get("message", "")
            added = store.add_contents_batch(classified_letters, text_field="message")
            total_added += added

        if classified_posts:
            for post in classified_posts:
                post["message"] = post.get("textBody") or post.get("body", "")
            added = store.add_contents_batch(classified_posts, text_field="message")
            total_added += added

        print(f"âœ“ {total_added}ê±´ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    # 4. í†µê³„ ë¶„ì„ (ì „ì£¼ ë¹„êµ)
    print(f"\n[4ë‹¨ê³„] í†µê³„ ë¶„ì„ (ì „ì£¼ ë¹„êµ)")
    analytics = WeeklyAnalytics()
    stats = analytics.analyze_weekly_data(
        classified_letters,
        classified_posts,
        previous_letters=prev_letters,
        previous_posts=prev_posts
    )

    total = stats["total_stats"]["this_week"]
    print(f"âœ“ ì „ì²´ í†µê³„: í¸ì§€ {total['letters']}ê±´, ê²Œì‹œê¸€ {total['posts']}ê±´")

    # 5. ë¦¬í¬íŠ¸ ìƒì„±
    print(f"\n[5ë‹¨ê³„] ë¦¬í¬íŠ¸ ìƒì„±")
    output_dir = "./reports"
    os.makedirs(output_dir, exist_ok=True)

    output_filename = f"weekly_report_{target_start}.md"
    output_path = os.path.join(output_dir, output_filename)

    generator = ReportGenerator()
    report = generator.generate_report(
        stats,
        target_start,
        target_end,
        output_path=output_path
    )

    print(f"âœ“ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
    print(f"âœ“ ì €ì¥ ìœ„ì¹˜: {output_path}")

    # 6. ì—‘ì…€ íŒŒì¼ ìƒì„±
    print(f"\n[6ë‹¨ê³„] ì—‘ì…€ íŒŒì¼ ìƒì„±")
    excel_filename = f"weekly_data_{target_start}.xlsx"
    excel_path = os.path.join(output_dir, excel_filename)
    export_to_excel(classified_letters, classified_posts, excel_path)
    print(f"âœ“ ì—‘ì…€ íŒŒì¼ ìƒì„±: {excel_path}")

    # 7. Notionì— ë¦¬í¬íŠ¸ ì—…ë¡œë“œ
    print(f"\n[7ë‹¨ê³„] Notion ì—…ë¡œë“œ")
    try:
        notion_client = NotionReportClient()
        week_label = SlackNotifier.get_week_label(target_start)

        # í˜ì´ì§€ ì œëª© ìƒì„±
        from datetime import datetime, timedelta
        start_formatted = datetime.strptime(target_start, '%Y-%m-%d').strftime('%Y.%m.%d')
        end_dt = datetime.strptime(target_end, '%Y-%m-%d')
        end_formatted = (end_dt - timedelta(days=1)).strftime('%m.%d')
        page_title = f"ì´ìš©ì ë°˜ì‘ ë¦¬í¬íŠ¸ ({start_formatted} ~ {end_formatted})"

        page_info = notion_client.create_report_page(
            title=page_title,
            markdown_content=report,
            start_date=target_start,
            end_date=target_end
        )

        notion_url = page_info["url"]
        print(f"âœ“ Notion í˜ì´ì§€ ìƒì„± ì™„ë£Œ")
        print(f"âœ“ URL: {notion_url}")
    except Exception as e:
        print(f"âš ï¸  Notion ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        notion_url = None

    # 8. Slack ì•Œë¦¼ ì „ì†¡ ë° ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ
    print(f"\n[8ë‹¨ê³„] Slack ì•Œë¦¼ ì „ì†¡")
    if notion_url:
        try:
            slack_client = SlackNotifier()
            result = slack_client.send_report_notification(
                week_label=week_label,
                start_date=target_start,
                end_date=target_end,
                notion_url=notion_url
            )

            if result.get("ok"):
                print(f"âœ“ Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")

                # ì—‘ì…€ íŒŒì¼ì„ ìŠ¤ë ˆë“œì— ì—…ë¡œë“œ
                message_ts = result.get("message_ts")
                if message_ts and os.path.exists(excel_path):
                    file_result = slack_client.upload_file_to_thread(
                        file_path=excel_path,
                        thread_ts=message_ts,
                        title=f"ì›ë³¸ ë°ì´í„° ({target_start})",
                        comment="ğŸ“ ë¼ë²¨ë§ëœ ì›ë³¸ ë°ì´í„° íŒŒì¼ì…ë‹ˆë‹¤."
                    )
                    if file_result.get("ok"):
                        print(f"âœ“ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
                    else:
                        print(f"âš ï¸  ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {file_result.get('error')}")
            else:
                print(f"âš ï¸  Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {result.get('error')}")
        except Exception as e:
            print(f"âš ï¸  Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
    else:
        print("âš ï¸  Notion URLì´ ì—†ì–´ Slack ì•Œë¦¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    print()
    print("="*60)
    print("âœ… ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ë° ê³µìœ  ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()
