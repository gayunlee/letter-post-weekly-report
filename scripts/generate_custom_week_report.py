"""íŠ¹ì • ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (ë‚ ì§œ ì§€ì •)"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.bigquery.client import BigQueryClient
from src.bigquery.queries import WeeklyDataQuery
from src.classifier.vector_classifier import VectorContentClassifier
from src.storage.data_store import ClassifiedDataStore
from src.vectorstore.chroma_store import ChromaVectorStore
from src.reporter.analytics import WeeklyAnalytics
from src.reporter.report_generator import ReportGenerator


def generate_week_data(start_date, end_date, data_store, master_info=None):
    """íŠ¹ì • ì£¼ê°„ì˜ ë°ì´í„° ìƒì„±"""
    print(f"\n{'='*60}")
    print(f"ğŸ“… {start_date} ~ {end_date} ë°ì´í„° ìƒì„±")
    print('='*60)

    if data_store.exists(start_date):
        print("âœ“ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„° - ê±´ë„ˆëœ€")
        data = data_store.load_weekly_data(start_date)
        return data['letters'], data['posts']

    print("BigQuery ì¡°íšŒ ì¤‘...")
    client = BigQueryClient()
    query = WeeklyDataQuery(client)

    # ë§ˆìŠ¤í„° ì •ë³´ ì¡°íšŒ (í•œ ë²ˆë§Œ)
    if master_info is None:
        print("ë§ˆìŠ¤í„° ì •ë³´ ì¡°íšŒ ì¤‘...")
        master_info = query.get_master_info()
        print(f"âœ“ {len(master_info)}ê°œ ë§ˆìŠ¤í„° ì •ë³´ ë¡œë“œ")

    weekly_data = query.get_weekly_data(start_date, end_date)

    letters = weekly_data['letters']
    posts = weekly_data['posts']
    print(f"âœ“ í¸ì§€ {len(letters)}ê±´, ê²Œì‹œê¸€ {len(posts)}ê±´ ì¡°íšŒ")

    if not letters and not posts:
        print("âŒ ë°ì´í„° ì—†ìŒ")
        return [], []

    # ë§ˆìŠ¤í„° ì´ë¦„ ì¶”ê°€ ë° ì‹¤ì œ masterId ì„¤ì •
    for item in letters:
        master_id = item.get('masterId')
        if master_id and master_id in master_info:
            item['masterName'] = master_info[master_id]['displayName']
            item['masterClubName'] = master_info[master_id]['clubName']
            item['actualMasterId'] = master_id
        else:
            item['masterName'] = 'Unknown'
            item['masterClubName'] = 'Unknown'
            item['actualMasterId'] = master_id or 'unknown'

    # ê²Œì‹œê¸€: postBoardIdë¥¼ ì‹¤ì œ masterIdë¡œ ë³€í™˜
    client_for_boards = BigQueryClient()
    board_to_master_query = f"""
    SELECT _id as boardId, masterId
    FROM `{client_for_boards.project_id}.us_plus.postboards`
    """
    board_to_master = {b['boardId']: b['masterId']
                       for b in client_for_boards.execute_query(board_to_master_query)}

    for item in posts:
        board_id = item.get('postBoardId')
        # postBoardIdë¥¼ ì‹¤ì œ masterIdë¡œ ë³€í™˜
        actual_master_id = board_to_master.get(board_id, board_id)

        if actual_master_id and actual_master_id in master_info:
            item['masterName'] = master_info[actual_master_id]['displayName']
            item['masterClubName'] = master_info[actual_master_id]['clubName']
            item['actualMasterId'] = actual_master_id
        else:
            item['masterName'] = 'Unknown'
            item['masterClubName'] = 'Unknown'
            item['actualMasterId'] = actual_master_id or 'unknown'

    print("ë¶„ë¥˜ ì¤‘...")
    classifier = VectorContentClassifier()
    classified_letters = classifier.classify_batch(letters, "message") if letters else []
    classified_posts = classifier.classify_batch(posts, "textBody") if posts else []

    print("ì €ì¥ ì¤‘...")
    data_store.save_weekly_data(start_date, end_date, classified_letters, classified_posts)
    print(f"âœ“ ì €ì¥ ì™„ë£Œ: {start_date}.json")

    return classified_letters, classified_posts


def main():
    # ëŒ€ìƒ ì£¼ê°„
    target_start = "2025-12-15"
    target_end = "2025-12-22"  # 12-21 ë‹¤ìŒë‚ ê¹Œì§€ (exclusive)

    # ì „ì£¼
    prev_start = "2025-12-08"
    prev_end = "2025-12-15"

    print("="*60)
    print("ğŸ“Š íŠ¹ì • ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±")
    print("="*60)

    data_store = ClassifiedDataStore()

    # 1. ì „ì£¼ ë°ì´í„° ìƒì„±
    print("\n[1ë‹¨ê³„] ì „ì£¼ ë°ì´í„° ìƒì„±")
    prev_letters, prev_posts = generate_week_data(prev_start, prev_end, data_store)

    # 2. ëŒ€ìƒ ì£¼ê°„ ë°ì´í„° ìƒì„±
    print("\n[2ë‹¨ê³„] ëŒ€ìƒ ì£¼ê°„ ë°ì´í„° ìƒì„±")
    classified_letters, classified_posts = generate_week_data(target_start, target_end, data_store)

    if not classified_letters and not classified_posts:
        print("\nâŒ ëŒ€ìƒ ì£¼ê°„ ë°ì´í„°ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
    print(f"\n[3ë‹¨ê³„] ë²¡í„° ìŠ¤í† ì–´ ì €ì¥")
    try:
        store = ChromaVectorStore(
            collection_name=f"week_{target_start}",
            persist_directory="./chroma_db"
        )
        store.reset()

        total_added = 0
        if classified_letters:
            for letter in classified_letters:
                letter["message"] = letter.get("message", "")
            added = store.add_contents_batch(classified_letters, text_field="message")
            total_added += added

        if classified_posts:
            for post in classified_posts:
                post["message"] = post.get("textBody") or post.get("body", "")
            added = store.add_contents_batch(classified_posts, text_field="message")
            total_added += added

        print(f"âœ“ {total_added}ê±´ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    # 4. í†µê³„ ë¶„ì„ (ì „ì£¼ ë¹„êµ)
    print(f"\n[4ë‹¨ê³„] í†µê³„ ë¶„ì„ (ì „ì£¼ ë¹„êµ)")
    analytics = WeeklyAnalytics()
    stats = analytics.analyze_weekly_data(
        classified_letters,
        classified_posts,
        previous_letters=prev_letters,
        previous_posts=prev_posts
    )

    total = stats["total_stats"]["this_week"]
    print(f"âœ“ ì „ì²´ í†µê³„: í¸ì§€ {total['letters']}ê±´, ê²Œì‹œê¸€ {total['posts']}ê±´")

    # 5. ë¦¬í¬íŠ¸ ìƒì„±
    print(f"\n[5ë‹¨ê³„] ë¦¬í¬íŠ¸ ìƒì„±")
    output_dir = "./reports"
    os.makedirs(output_dir, exist_ok=True)

    output_filename = f"weekly_report_{target_start}.md"
    output_path = os.path.join(output_dir, output_filename)

    generator = ReportGenerator()
    report = generator.generate_report(
        stats,
        target_start,
        target_end,
        output_path=output_path
    )

    print(f"âœ“ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
    print(f"âœ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print()

    print("="*60)
    print("âœ… ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()
