"""
2ì¶•(Topic Ã— Sentiment) ë¼ë²¨ë§ ë°ì´í„° ì „ìˆ˜ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸

labeled_2axis.jsonì˜ 3,641ê±´ì— ëŒ€í•´ ì˜ë„ ê¸°ë°˜ ê·œì¹™ì„ ì ìš©í•˜ì—¬
Topicê³¼ Sentimentë¥¼ ê²€ì¦í•˜ê³  ìˆ˜ì •í•œë‹¤.
"""

import json
import re
from collections import Counter, defaultdict
from pathlib import Path

BASE_DIR = Path(__file__).parent.parent
INPUT_FILE = BASE_DIR / "data" / "training_data" / "labeled_2axis.json"
OUTPUT_FILE = BASE_DIR / "data" / "training_data" / "labeled_2axis_reviewed.json"
UNCERTAIN_FILE = BASE_DIR / "data" / "training_data" / "uncertain_items.json"

# ============================================================
# 1. í‚¤ì›Œë“œ / íŒ¨í„´ ì‚¬ì „
# ============================================================

# ë§ˆìŠ¤í„° ì½˜í…ì¸  ê´€ë ¨ í‚¤ì›Œë“œ (ê°•ì˜, ë¦¬í¬íŠ¸, ë°©ì†¡ ë“±ì— ëŒ€í•œ ë°˜ì‘)
CONTENT_REACTION_PATTERNS = [
    r'ê°•ì˜.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*ê°•ì˜',
    r'ë¦¬í¬íŠ¸.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*ë¦¬í¬íŠ¸',
    r'ë°©ì†¡.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*ë°©ì†¡',
    r'ë¶„ì„.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*ë¶„ì„',
    r'ì˜ìƒ.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*ì˜ìƒ',
    r'ì¿ í‚¤.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*ì¿ í‚¤',
    r'(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„).*(?:ì˜¬ë ¤|ì¨|ì ì–´)',
    r'ê¸€.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'ì½˜í…ì¸ .*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'êµìœ¡.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
    r'ë¼ì´ë¸Œ.*(?:ì˜|ê°ì‚¬|ë„ì›€|ì¢‹|ë•ë¶„)',
]

# ë§ˆìŠ¤í„°ë¥¼ ì§€ì¹­í•˜ëŠ” íŒ¨í„´ (ì½˜í…ì¸  ë°˜ì‘ì˜ ë‹¨ì„œ)
MASTER_MENTION_PATTERNS = [
    r'(?:ìŒ¤|ì„ ìƒë‹˜|êµìˆ˜ë‹˜|ì‘ê°€ë‹˜|ëŒ€í‘œë‹˜|ì›ì¥ë‹˜|ë§ˆìŠ¤í„°ë‹˜|ë‹˜).*(?:ë•ë¶„|ê°ì‚¬|ê°ë™|ì¢‹|ë°°ìš°|ê³µë¶€|ì„±ì¥)',
    r'(?:ë•ë¶„|ê°ì‚¬|ê°ë™|ì¢‹|ë°°ìš°|ê³µë¶€|ì„±ì¥).*(?:ìŒ¤|ì„ ìƒë‹˜|êµìˆ˜ë‹˜|ì‘ê°€ë‹˜|ëŒ€í‘œë‹˜|ì›ì¥ë‹˜|ë§ˆìŠ¤í„°ë‹˜)',
]

# ë§ˆìŠ¤í„° ì½˜í…ì¸ ì— ëŒ€í•œ ê°ì‚¬/ê°ë™ (textì— ë§ˆìŠ¤í„° ì–¸ê¸‰ + ê°ì‚¬)
MASTER_GRATITUDE_PATTERNS = [
    r'(?:ìŒ¤|ì„ ìƒë‹˜|êµìˆ˜ë‹˜|ì‘ê°€ë‹˜|ëŒ€í‘œë‹˜|ì›ì¥ë‹˜|ë§ˆìŠ¤í„°ë‹˜|ë‹˜).*(?:ë•ë¶„|ê°ì‚¬í•©ë‹ˆë‹¤|ê³ ë§™ìŠµë‹ˆë‹¤|ê³ ë§ˆì›Œìš”|ê°ë™)',
    r'(?:ë•ë¶„ì—|ê°ì‚¬í•©ë‹ˆë‹¤|ê³ ë§™ìŠµë‹ˆë‹¤|ê³ ë§ˆì›Œìš”|ê°ë™).*(?:ìŒ¤|ì„ ìƒë‹˜|êµìˆ˜ë‹˜|ì‘ê°€ë‹˜|ëŒ€í‘œë‹˜|ì›ì¥ë‹˜|ë§ˆìŠ¤í„°ë‹˜)',
    r'(?:ë§Œë‚˜ì„œ|ë§Œë‚œê²ƒ|ì•Œê²Œë˜ì–´|ì•Œê²Œë¼ì„œ).*(?:ê°ì‚¬|ë‹¤í–‰|í–‰ë³µ|í–‰ìš´|ë³µ)',
    r'(?:ì‚¶|ì¸ìƒ|íˆ¬ì).*(?:ë³€|ë°”ë€Œ|ë‹¬ë¼).*(?:ê°ì‚¬|ë•ë¶„)',
    r'(?:ë°°ìš°|ê³µë¶€|ì„±ì¥).*(?:ê°ì‚¬|ë•ë¶„)',
]

# íˆ¬ì í† ë¡ /ì§ˆë¬¸/ë§¤ë§¤ ë³´ê³  íŒ¨í„´
INVESTMENT_DISCUSSION_PATTERNS = [
    r'(?:PER|PBR|ROE|ROA|EPS|BPS|ì‹œì´|ì‹œê°€ì´ì•¡|ë°°ë‹¹)',
    r'(?:ë§¤ìˆ˜|ë§¤ë„|ì†ì ˆ|ìµì ˆ|ë¬¼íƒ€ê¸°|ì¶”ë§¤|ì¶”ê°€ë§¤ìˆ˜|ë¶„í• ë§¤ìˆ˜|ë¶„í• ë§¤ë„|ë¦¬ë°¸ëŸ°ì‹±)',
    r'(?:í¬íŠ¸í´ë¦¬ì˜¤|í¬í´|ë¹„ì¤‘|ì„¹í„°|ì—…ì¢…|ì¢…ëª©).*(?:ì§ˆë¬¸|ê¶ê¸ˆ|ì–´ë–»|ì¶”ì²œ|ì˜ê²¬)',
    r'(?:ì§ˆë¬¸|ê¶ê¸ˆ|ì–´ë–»|ì¶”ì²œ|ì˜ê²¬).*(?:í¬íŠ¸í´ë¦¬ì˜¤|í¬í´|ë¹„ì¤‘|ì„¹í„°|ì—…ì¢…|ì¢…ëª©)',
    r'(?:ìƒìŠ¹|í•˜ë½|ê¸‰ë“±|ê¸‰ë½|ì¡°ì •|ë°˜ë“±|ëŒíŒŒ|ì§€ì§€|ì €í•­).*(?:ì˜ˆìƒ|ì „ë§|ìƒê°|ì˜ê²¬)',
    r'(?:ìˆ˜ìµë¥ |ì†ì‹¤ë¥ |ìˆ˜ìµê¸ˆ|ì†ì‹¤ê¸ˆ|í‰ë‹¨|í‰ê· ë‹¨ê°€)',
    r'(?:ì–¸ì œ|ì–¼ë§ˆ|ëª‡ì£¼|ëª‡í¼).*(?:ë§¤ìˆ˜|ë§¤ë„|ì‚¬|íŒ”)',
    r'(?:ë³´ìœ |ë§¤ìˆ˜|ë§¤ë„).*(?:í• ê¹Œ|í•´ì•¼|í•˜ëŠ”ê²Œ|ì¢‹ì„ê¹Œ)',
    r'(?:ëª©í‘œê°€|ëª©í‘œì£¼ê°€|ì ì •ê°€|ì ì •ì£¼ê°€)',
]

# íˆ¬ì ì£¼ì œ í‚¤ì›Œë“œ (ë‹¨ì–´ ìˆ˜ì¤€)
INVESTMENT_KEYWORDS = [
    'ë§¤ìˆ˜', 'ë§¤ë„', 'ì†ì ˆ', 'ìµì ˆ', 'ë¬¼íƒ€ê¸°', 'ì¶”ë§¤', 'ì¶”ê°€ë§¤ìˆ˜', 'ë¶„í• ë§¤ìˆ˜',
    'PER', 'PBR', 'ROE', 'EPS', 'ì‹œì´', 'ë°°ë‹¹', 'ì‹¤ì ', 'ì–´ë‹',
    'í¬íŠ¸í´ë¦¬ì˜¤', 'í¬í´', 'ë¹„ì¤‘ì¡°ì ˆ', 'ë¦¬ë°¸ëŸ°ì‹±',
    'ìƒí•œê°€', 'í•˜í•œê°€', 'ê¸‰ë“±', 'ê¸‰ë½', 'ê°­ìƒ', 'ê°­í•˜',
    'ì°¨íŠ¸', 'ì´í‰ì„ ', 'ë³¼ë¦°ì €', 'ê±°ë˜ëŸ‰', 'ìˆ˜ê¸‰', 'ì™¸êµ­ì¸', 'ê¸°ê´€', 'ì—°ê¸°ê¸ˆ',
    'ê³µë§¤ë„', 'ì‹ ìš©ì”ê³ ', 'ëŒ€ì°¨ì”ê³ ',
]

# íŠ¹ì • ì¢…ëª©ëª… íŒ¨í„´ (íˆ¬ì ì´ì•¼ê¸°ì˜ ë‹¨ì„œ)
STOCK_NAMES = [
    'ë‘ì‚°', 'ì—ë„ˆë¹Œë¦¬í‹°', 'ë‘ë¹Œ', 'í•œí™”ì˜¤ì…˜', 'í•œí™”', 'HDí˜„ëŒ€',
    'ì‚¼ì„±ì „ì', 'ì‚¼ì „', 'SKí•˜ì´ë‹‰ìŠ¤', 'í•˜ì´ë‹‰ìŠ¤', 'LGì „ì', 'LGí™”í•™',
    'LGë””ìŠ¤í”Œë ˆì´', 'LGë””í”Œ', 'í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'íŒŒë¯¸ì…€', 'ì— ë¡œ',
    'DLì´ì•¤ì”¨', 'ë‘ì‚°ìš°', 'í•œêµ­ì „ë ¥', 'í•œì „', 'ì‚¼ì„±ì—ìŠ¤í”¼',
    'OCI', 'ì„í•€ì§€', 'í•œì˜¨ì‹œìŠ¤í…œ', 'ì½”ìŠ¤í”¼', 'ì½”ìŠ¤ë‹¥', 'ë‚˜ìŠ¤ë‹¥',
    'S&P', 'ETF',
]

# ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ íŒ¨í„´ (ì¸ì‚¬, ì•ˆë¶€, ì¶•í•˜, ìœ„ë¡œ)
COMMUNITY_PATTERNS = [
    r'ì•ˆë…•í•˜ì„¸ìš”[.!?\s]*$',
    r'(?:ê±´ê°•|ëª¸ì¡°ë¦¬|ì»¨ë””ì…˜).*(?:ì±™ê¸°|ì¡°ì‹¬|ìœ ì˜|ì˜|í•˜ì„¸ìš”)',
    r'(?:ëª…ë³µ|ì‚¼ê°€|ì• ë„|ìœ„ë¡œ|ì¶”ëª¨)',
    r'(?:ìƒˆí•´|ì„¤|ì¶”ì„|ëª…ì ˆ|ìƒì¼|í¬ë¦¬ìŠ¤ë§ˆìŠ¤|ì—°ë§).*(?:ë³µ|ì¶•í•˜|ê¸°ì›)',
    r'(?:ì¶•í•˜|ì‘ì›|íŒŒì´íŒ…|í™”ì´íŒ…|í™§íŒ…|í˜ë‚´|ì˜|ì¢‹|í•´ìš”|í•©ì‹œë‹¤|í•˜ì„¸ìš”)[!â™¡â™¥]*\s*$',
    r'^(?:ì¶•í•˜|ì‘ì›|íŒŒì´íŒ…|í™”ì´íŒ…|í™§íŒ…|í˜ë‚´)',
    r'(?:ë°˜ê°‘ìŠµë‹ˆë‹¤|ë°˜ê°€ì›Œìš”|ì˜ë¶€íƒ|ì˜ ë¶€íƒ)',
    r'(?:ë‹¤ë“¤|ëª¨ë‘|í•™ìš°|ì—¬ëŸ¬ë¶„).*(?:í™§íŒ…|í™”ì´íŒ…|íŒŒì´íŒ…|í˜ë‚´|ì¢‹ì€|í•˜ë£¨)',
    r'(?:ì¢‹ì€|ì¦ê±°ìš´|í–‰ë³µí•œ).*(?:í•˜ë£¨|ì£¼ë§|í•œì£¼|ì €ë…|ì•„ì¹¨)',
    r'(?:ê°ê¸°|ë‚ ì”¨|ì¶”ìœ„|ë”ìœ„).*(?:ì¡°ì‹¬|ì£¼ì˜|ì±™ê¸°)',
]

# ì„œë¹„ìŠ¤ ì´ìŠˆ íŒ¨í„´ (ë³´ë‹¤ ì—„ê²©í•˜ê²Œ: í”Œë«í¼/ì•± ê¸°ëŠ¥, ê²°ì œ, êµ¬ë… ìš´ì˜ì— ëŒ€í•œ ì§ì ‘ì  ì´ìŠˆ)
SERVICE_PATTERNS = [
    r'(?:í™˜ë¶ˆ|ê²°ì œ|êµ¬ë…|í•´ì§€|ì·¨ì†Œ).*(?:ìš”ì²­|ë¶€íƒ|í•´ì£¼|ì•ˆë¨|ì•ˆë˜|ì•Šë¨|ì–´ë–»ê²Œ)',
    r'(?:ì•±|ì–´í”Œ|ì‚¬ì´íŠ¸|í”Œë«í¼|ì‹œìŠ¤í…œ).*(?:ì˜¤ë¥˜|ì—ëŸ¬|ë²„ê·¸|ì•ˆë¨|ì•ˆë˜|ëŠë¦¼|ë¬¸ì œ|ê°œì„ )',
    r'(?:ì„¸ë¯¸ë‚˜|ì˜¤í”„ë¼ì¸).*(?:ì‹ ì²­|ì ‘ìˆ˜|ì˜ˆì•½|í™•ì¸).*(?:ì•ˆë¨|ì•ˆë˜|ì–´ë–»ê²Œ)',
    r'(?:ë©¤ë²„ì‹­|íšŒì›).*(?:ê°€ì…|íƒˆí‡´|ë“±ê¸‰|ê´€ë¦¬).*(?:ì–´ë–»ê²Œ|ì•ˆë¨|ì•ˆë˜|ë°©ë²•|ë¶ˆë§Œ|ë¶€íƒ)',
    r'(?:í”„ë¦¬ë¯¸ì—„|ìœ ë£Œ|ë¬´ë£Œ|êµ¬ë…).*(?:ê°€ì…|ë°©ë²•|ì–´ë–»ê²Œ)',
    r'(?:ëŒ“ê¸€|ê¸°ëŠ¥|ì•Œë¦¼|í‘¸ì‹œ).*(?:ì—´ì–´|ì•ˆë¨|ì•ˆë˜|ì—†|ì¶”ê°€|í•´ì£¼)',
    r'(?:ì–´ë–»ê²Œ).*(?:ê°€ì…|ì‹ ì²­|ê²°ì œ|êµ¬ë…)',
    r'(?:íƒˆí‡´|í™˜ë¶ˆ).*(?:í•©ë‹ˆë‹¤|í•˜ê² |í• ê²Œ|í•´ì£¼)',
    r'(?:ì†Œí†µ|ìŒë°©í–¥|ëŒ“ê¸€).*(?:ì•ˆë˜|ì•ˆë¨|ì—†|ì—´ì–´|í•´ì£¼)',
    r'(?:ìš´ì˜|ê´€ë¦¬).*(?:ì•ˆí•˜|ë¶€ì¡±|ë¶€ì‹¤|ì•„ì‰½|ë¶ˆë§Œ)',
]

# ê°ì • í‚¤ì›Œë“œ
POSITIVE_KEYWORDS = [
    'ê°ì‚¬', 'ê³ ë§™', 'ê°ë™', 'ì¢‹ì•„', 'ì¢‹ì€', 'ìµœê³ ', 'ëŒ€ë‹¨', 'í›Œë¥­', 'ë©‹ì§€', 'ë©‹ì§„',
    'í–‰ë³µ', 'ê¸°ì˜', 'ê¸°ë»', 'ì¦ê±°', 'ë¿Œë“¯', 'ì„¤ë ˆ', 'ë“ ë“ ', 'ë”°ëœ»', 'ì‚¬ë‘',
    'ì¹­ì°¬', 'ì¡´ê²½', 'ì‘ì›', 'ê²©ë ¤', 'íŒŒì´íŒ…', 'í™”ì´íŒ…', 'í™§íŒ…', 'í˜ë‚´',
    'ìˆ˜ìµ', 'í‘ì', 'í”ŒëŸ¬ìŠ¤', 'ì˜¬ë', 'ë‚ ì•„', 'ì¶•í•˜', 'ë§Œì¡±', 'í¸ì•ˆ', 'ì•ˆì •',
    'ë³µ', 'ê±´ìŠ¹', 'ê±´ê°•í•˜', 'ì¶•ë³µ',
]

NEGATIVE_KEYWORDS = [
    'ë¶ˆë§Œ', 'ì‹¤ë§', 'ë‹µë‹µ', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ì§œì¦', 'í™”ê°€', 'ë¶„ë…¸', 'ì†ìƒ',
    'í˜ë“¤', 'í˜ë“ ', 'ê´´ë¡œ', 'ê³ í†µ', 'ìŠ¬í”„', 'ì„œê¸€', 'ì”ì“¸', 'í—ˆíƒˆ', 'ì•„ì‰½',
    'ë¶ˆí¸', 'ë¬¸ì œ', 'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ì•ˆë¨', 'í™˜ë¶ˆ', 'í•´ì§€',
    'ì†ì‹¤', 'ë§ˆì´ë„ˆìŠ¤', '-', 'ë¹ ì§€', 'ë–¨ì–´', 'í­ë½', 'ê¸‰ë½', 'í•˜ë½',
    'ì£½ê²„', 'ì£½ê² ', 'ëª»í•˜ê² ', 'ë¬´ë„ˆ', 'ê¹¡í†µ', 'ë¬¼ë ¸',
]

NEUTRAL_INDICATORS = [
    r'\?[\s]*$',  # ë¬¼ìŒí‘œë¡œ ëë‚¨
    r'(?:ê¶ê¸ˆ|ì§ˆë¬¸|ì—¬ì­¤|ì—¬ì­ˆ|ë¬¸ì˜|ì•Œë ¤ì£¼|ì„¤ëª…|ë¶€íƒ)',
    r'(?:ì¸ê°€ìš”|ì¼ê¹Œìš”|í• ê¹Œìš”|ë˜ë‚˜ìš”|ìˆë‚˜ìš”|ë§ë‚˜ìš”|ê±´ê°€ìš”)',
    r'(?:ì–´ë–»ê²Œ|ì–´ë–¤|ì–¼ë§ˆ|ëª‡|ì–¸ì œ)',
]


# ============================================================
# 2. íŒì • í•¨ìˆ˜ë“¤
# ============================================================

def has_pattern(text, patterns):
    """í…ìŠ¤íŠ¸ì— íŒ¨í„´ ëª©ë¡ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹˜ë˜ë©´ True"""
    for p in patterns:
        if re.search(p, text, re.IGNORECASE):
            return True
    return False

def count_keywords(text, keywords):
    """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë“±ì¥ íšŸìˆ˜"""
    count = 0
    for kw in keywords:
        count += len(re.findall(re.escape(kw), text, re.IGNORECASE))
    return count

def has_stock_mention(text):
    """ì¢…ëª©ëª… ì–¸ê¸‰ ì—¬ë¶€ (ë‹‰ë„¤ì„/ì‚¬ëŒì´ë¦„ì— í¬í•¨ëœ ì¢…ëª©ëª…ì€ ì œì™¸)"""
    # ë‹‰ë„¤ì„ íŒ¨í„´ ì œê±°: "OOë‹˜", "OOìŒ¤" ë“±ì—ì„œ ì¢…ëª©ëª…ì´ í¬í•¨ëœ ê²½ìš°
    # e.g. "ë‘ì‚°ì‚¬ë‘ë‹˜", "LGíŒ¬ë‹˜" ë“±
    cleaned = re.sub(r'\S*ë‹˜', '', text)
    cleaned = re.sub(r'\S*ìŒ¤', '', cleaned)
    cleaned = re.sub(r'\S*ë°˜íŠ¸\S*', '', cleaned)  # ë¸”ë£¨ë°˜íŠ¸ë‹˜ ë“±

    for name in STOCK_NAMES:
        if name.lower() in cleaned.lower():
            return True
    return False

def has_question(text):
    """ì§ˆë¬¸ í¬í•¨ ì—¬ë¶€"""
    if '?' in text or 'ìš”?' in text:
        return True
    question_patterns = [
        r'(?:ê¶ê¸ˆ|ì§ˆë¬¸|ì—¬ì­¤|ì—¬ì­ˆ|ë¬¸ì˜)',
        r'(?:ì¸ê°€ìš”|ì¼ê¹Œìš”|í• ê¹Œìš”|ë˜ë‚˜ìš”|ìˆë‚˜ìš”|ë§ë‚˜ìš”|ê±´ê°€ìš”|í•˜ë‚˜ìš”)',
        r'(?:ì–´ë–»ê²Œ|ì–´ë–¤|ì–¼ë§ˆë‚˜|ëª‡|ì–¸ì œ).*(?:ìš”|ê¹Œ)',
        r'(?:ì•Œë ¤ì£¼|ì„¤ëª…í•´|ë¶€íƒë“œ)',
    ]
    return has_pattern(text, question_patterns)

def is_primarily_investment(text):
    """íˆ¬ì í† ë¡ /ì§ˆë¬¸/ë§¤ë§¤ë³´ê³ ê°€ ì£¼ ëª©ì ì¸ì§€"""
    inv_score = 0
    # íˆ¬ì í† ë¡  íŒ¨í„´ ë§¤ì¹˜
    if has_pattern(text, INVESTMENT_DISCUSSION_PATTERNS):
        inv_score += 3
    # íˆ¬ì í‚¤ì›Œë“œ ìˆ˜
    inv_kw_count = count_keywords(text, INVESTMENT_KEYWORDS)
    inv_score += min(inv_kw_count, 5)
    # ì¢…ëª©ëª… ì–¸ê¸‰ (ë‹‰ë„¤ì„ ì œì™¸)
    cleaned_text = re.sub(r'\S*ë‹˜', '', text)
    cleaned_text = re.sub(r'\S*ìŒ¤', '', cleaned_text)
    cleaned_text = re.sub(r'\S*ë°˜íŠ¸\S*', '', cleaned_text)
    stock_count = sum(1 for name in STOCK_NAMES if name.lower() in cleaned_text.lower())
    inv_score += min(stock_count * 2, 6)
    # íˆ¬ì ì§ˆë¬¸
    if has_question(text) and (inv_kw_count > 0 or stock_count > 0):
        inv_score += 2
    return inv_score

def is_primarily_content_reaction(text):
    """ë§ˆìŠ¤í„° ì½˜í…ì¸  ë°˜ì‘ì´ ì£¼ ëª©ì ì¸ì§€"""
    cr_score = 0
    if has_pattern(text, CONTENT_REACTION_PATTERNS):
        cr_score += 4
    if has_pattern(text, MASTER_GRATITUDE_PATTERNS):
        cr_score += 3
    if has_pattern(text, MASTER_MENTION_PATTERNS):
        cr_score += 2
    # "ë•ë¶„ì—" ë‹¨ë… ì‚¬ìš©
    if re.search(r'ë•ë¶„', text):
        cr_score += 1
    return cr_score

def is_primarily_community(text):
    """ì»¤ë®¤ë‹ˆí‹° ì†Œí†µì´ ì£¼ ëª©ì ì¸ì§€"""
    comm_score = 0
    if has_pattern(text, COMMUNITY_PATTERNS):
        comm_score += 3
    # ì§§ì€ ì¸ì‚¬/ê²©ë ¤
    if len(text) < 30:
        greeting_patterns = [r'í™”ì´íŒ…', r'í™§íŒ…', r'íŒŒì´íŒ…', r'í˜ë‚´', r'ê°ì‚¬', r'ì‘ì›',
                           r'ì•ˆë…•', r'ë°˜ê°‘', r'ì¶•í•˜', r'ìƒˆí•´', r'ëª…ë³µ']
        if has_pattern(text, greeting_patterns):
            comm_score += 3
    # ëª…ë³µ/ìœ„ë¡œ
    if re.search(r'(?:ëª…ë³µ|ì‚¼ê°€|ì• ë„|ìœ„ë¡œ|ì¶”ëª¨|ì˜ë©´)', text):
        comm_score += 5
    # ê±´ê°• ì±™ê¸°ì„¸ìš” ë¥˜
    if re.search(r'(?:ê±´ê°•|ëª¸ì¡°ë¦¬|ì»¨ë””ì…˜).*(?:ì±™ê¸°|í•˜ì„¸ìš”|ì¡°ì‹¬)', text):
        comm_score += 3
    # ì•ˆë¶€/ì¸ì‚¬ê°€ ì£¼ ë‚´ìš©ì´ê³  íˆ¬ì ë‚´ìš©ì´ ì ì€ ê²½ìš°
    return comm_score

def is_primarily_service(text):
    """ì„œë¹„ìŠ¤ ì´ìŠˆê°€ ì£¼ ëª©ì ì¸ì§€"""
    svc_score = 0
    if has_pattern(text, SERVICE_PATTERNS):
        svc_score += 4
    # ì„œë¹„ìŠ¤ ì´ìŠˆ í‚¤ì›Œë“œ: ë‹¨ìˆœ "ê°€ì…", "ì–´í”Œ", "ë©¤ë²„ì‹­" ë“±ì€ ë§¥ë½ì— ë”°ë¼ íˆ¬ì/ì»¤ë®¤ë‹ˆí‹°ì—ì„œë„ ì‚¬ìš©ë˜ë¯€ë¡œ
    # ì„œë¹„ìŠ¤ ìš´ì˜ ë§¥ë½ì—ì„œë§Œ ì ìˆ˜ ë¶€ì—¬
    strong_svc_keywords = ['í™˜ë¶ˆ', 'í•´ì§€', 'ì·¨ì†Œ', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'í”„ë¦¬ë¯¸ì—„ë°˜']
    svc_score += min(count_keywords(text, strong_svc_keywords) * 3, 6)

    # "ê°€ì…", "ë©¤ë²„ì‹­" ë“±ì€ ì„œë¹„ìŠ¤ ê´€ë ¨ ë™ì‚¬ì™€ í•¨ê»˜ ì‚¬ìš©ë  ë•Œë§Œ ì ìˆ˜ ë¶€ì—¬
    contextual_svc = [
        r'(?:ê°€ì…|ë©¤ë²„ì‹­|êµ¬ë…).*(?:ì–´ë–»ê²Œ|ë°©ë²•|ì•ˆë¨|ì•ˆë˜|í•´ì§€|ì·¨ì†Œ|í™˜ë¶ˆ)',
        r'(?:ì–´ë–»ê²Œ|ë°©ë²•).*(?:ê°€ì…|ë©¤ë²„ì‹­|êµ¬ë…)',
    ]
    if has_pattern(text, contextual_svc):
        svc_score += 2
    return svc_score


def determine_sentiment(text, current_sentiment):
    """Sentiment ì¬íŒì •"""
    pos_count = count_keywords(text, POSITIVE_KEYWORDS)
    neg_count = count_keywords(text, NEGATIVE_KEYWORDS)
    is_question = has_question(text)

    # ê·œì¹™ ê¸°ë°˜ ë³´ì • ì‚¬ìœ ë¥¼ í•¨ê»˜ ë°˜í™˜
    reasons = []

    # 1) ì§ˆë¬¸ì´ ì£¼ ë‚´ìš©ì´ë©´ì„œ ê°ì • í‘œí˜„ì´ ì•½í•œ ê²½ìš° â†’ ì¤‘ë¦½
    if is_question and pos_count <= 1 and neg_count == 0:
        if current_sentiment == 'ê¸ì •':
            reasons.append("ì§ˆë¬¸ì´ ì£¼ ë‚´ìš©, ê¸ì • í‘œí˜„ ë¯¸ì•½")
            return 'ì¤‘ë¦½', reasons

    # 2) ì§ˆë¬¸ì´ í¬í•¨ë˜ì–´ë„ ì „ì²´ í†¤ì´ ê°ì‚¬/ê¸ì •ì´ ê°•í•˜ë©´ â†’ ê¸ì • ìœ ì§€
    if is_question and pos_count >= 3 and neg_count == 0:
        if current_sentiment == 'ì¤‘ë¦½':
            reasons.append("ì§ˆë¬¸ í¬í•¨ì´ë‚˜ ê¸ì • í†¤ì´ ê°•í•¨(ê°ì‚¬+ì§ˆë¬¸)")
            return 'ê¸ì •', reasons

    # 3) ë¶€ì • í‚¤ì›Œë“œê°€ ìˆì§€ë§Œ ê²©ë ¤/ì‘ì› ë§¥ë½ì´ë©´ â†’ ê¸ì •
    encouragement_patterns = [
        r'(?:í˜ë“¤|ì–´ë µ|ê±±ì •).*(?:ì§€ë§Œ|í•´ë„|ê² ì§€ë§Œ).*(?:í™”ì´íŒ…|í™§íŒ…|íŒŒì´íŒ…|í˜ë‚´|ì‘ì›|í•¨ê»˜|ê°™ì´|ì´ê²¨)',
        r'(?:ì†ì‹¤|í•˜ë½|ë§ˆì´ë„ˆìŠ¤).*(?:ë‘ë ¤ì›Œ|ê±±ì •).*(?:ë§ˆì„¸ìš”|ë§ê³ |ì•Šì•„ë„)',
        r'(?:í˜ë“¤|ê´´ë¡œ|ì–´ë µ).*(?:ì§€ë§Œ|í•´ë„).*(?:ê°ì‚¬|ë‹¤í–‰|í–‰ë³µ|ì¢‹)',
    ]
    if has_pattern(text, encouragement_patterns) and pos_count >= neg_count:
        if current_sentiment == 'ë¶€ì •':
            reasons.append("ê²©ë ¤/ì‘ì› ë§¥ë½ì—ì„œ ë¶€ì • í‚¤ì›Œë“œ ì‚¬ìš©")
            return 'ê¸ì •', reasons

    # 4) ì •ì¤‘í•œ ë¶ˆë§Œ/ìš”ì²­ (í‚¤ì›Œë“œë¡œ ì•ˆ ì¡íˆëŠ” ë¶€ì •)
    polite_complaint_patterns = [
        r'(?:í•´ì£¼ì…¨ìœ¼ë©´|í•´ì£¼ì‹œë©´|ë°”ëë‹ˆë‹¤|ë¶€íƒë“œë¦½ë‹ˆë‹¤).*(?:ì•„ì‰½|ê°œì„ |ë¶ˆí¸)',
        r'(?:ì•„ì‰½|ê°œì„ |ë¶ˆí¸).*(?:í•´ì£¼ì…¨ìœ¼ë©´|í•´ì£¼ì‹œë©´|ë°”ëë‹ˆë‹¤|ë¶€íƒë“œë¦½ë‹ˆë‹¤)',
        r'(?:ì™œ|ì–´ì§¸ì„œ).*(?:ì•ˆ|ì—†|ëª»).*(?:ì£¼ì‹œ|í•´ì£¼|í•˜ë‚˜ìš”)',
        r'(?:ë‹µë‹µ|ë¶ˆí¸|ì•„ì‰½|ì„œìš´).*(?:ì˜ê²¬|ë§ì”€|ë“œë¦½ë‹ˆë‹¤|ë´…ë‹ˆë‹¤|í•©ë‹ˆë‹¤)',
    ]
    if has_pattern(text, polite_complaint_patterns) and current_sentiment != 'ë¶€ì •':
        if neg_count >= 1 or has_pattern(text, polite_complaint_patterns):
            reasons.append("ì •ì¤‘í•œ ë¶ˆë§Œ/ìš”ì²­")
            return 'ë¶€ì •', reasons

    # 5) ëª…í™•í•œ ê°ì • ë¶ˆì¼ì¹˜ ë³´ì •
    # ê¸ì •ìœ¼ë¡œ ë˜ì–´ìˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ë¶€ì •ì´ í›¨ì”¬ ê°•í•œ ê²½ìš°
    if current_sentiment == 'ê¸ì •' and neg_count >= 3 and pos_count <= 1:
        reasons.append(f"ë¶€ì • í‚¤ì›Œë“œ({neg_count})ê°€ ê¸ì •({pos_count})ë³´ë‹¤ í›¨ì”¬ ë§ìŒ")
        return 'ë¶€ì •', reasons

    # ë¶€ì •ìœ¼ë¡œ ë˜ì–´ìˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ê¸ì •ì´ í›¨ì”¬ ê°•í•œ ê²½ìš°
    if current_sentiment == 'ë¶€ì •' and pos_count >= 3 and neg_count <= 1:
        reasons.append(f"ê¸ì • í‚¤ì›Œë“œ({pos_count})ê°€ ë¶€ì •({neg_count})ë³´ë‹¤ í›¨ì”¬ ë§ìŒ")
        return 'ê¸ì •', reasons

    # 6) ì¤‘ë¦½ì¸ë° ê°•í•œ ê°ì •ì´ ìˆëŠ” ê²½ìš°
    if current_sentiment == 'ì¤‘ë¦½':
        if pos_count >= 3 and neg_count == 0:
            reasons.append(f"ê¸ì • í‚¤ì›Œë“œ ë‹¤ìˆ˜({pos_count}), ë¶€ì • ì—†ìŒ")
            return 'ê¸ì •', reasons
        if neg_count >= 3 and pos_count == 0:
            reasons.append(f"ë¶€ì • í‚¤ì›Œë“œ ë‹¤ìˆ˜({neg_count}), ê¸ì • ì—†ìŒ")
            return 'ë¶€ì •', reasons

    # 7) ê¸ì •ì¸ë° ê°ì • í‘œí˜„ì´ ì „í˜€ ì—†ê³  ì‚¬ì‹¤ ê¸°ìˆ /ì •ë³´ë§Œ ìˆëŠ” ê²½ìš°
    if current_sentiment == 'ê¸ì •' and pos_count == 0 and neg_count == 0:
        # ì´ëª¨í‹°ì½˜ë§Œ ìˆëŠ” ê²½ìš°ëŠ” ìœ ì§€
        if not re.search(r'[â™¡â™¥â¤ğŸ’šğŸ€ğŸ˜ğŸ˜Šâ˜ºï¸ğŸ‘ğŸ’ªğŸ‰]', text):
            if len(text) > 20:  # ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸ì¸ë° ê°ì • í‘œí˜„ì´ ì—†ìœ¼ë©´
                reasons.append("ê°ì • í‘œí˜„ ì—†ì´ ì‚¬ì‹¤/ì •ë³´ ê¸°ìˆ ")
                return 'ì¤‘ë¦½', reasons

    # 8) ëª…í™•í•œ ì†ì‹¤/ê³ í†µ í‘œí˜„
    loss_patterns = [
        r'(?:ì†ì‹¤|ë§ˆì´ë„ˆìŠ¤|-\d+%).*(?:í¬|ì»¤|ë„ˆë¬´|ë§|ì‹¬ê°|ê°ë‹¹)',
        r'(?:ê¹¡í†µ|ë¬¼ë ¸|ë¬¼ë ¤|ì£½ê² |ì£½ê²„|ëª»í•˜ê² )',
        r'(?:ë„ˆë¬´|ë§ì´|í¬ê²Œ).*(?:í˜ë“¤|ê´´ë¡œ|ê³ í†µ|ë¹ ì§€|ë–¨ì–´)',
    ]
    if has_pattern(text, loss_patterns) and current_sentiment != 'ë¶€ì •':
        reasons.append("ëª…í™•í•œ ì†ì‹¤/ê³ í†µ í‘œí˜„")
        return 'ë¶€ì •', reasons

    # 9) ì‘ì›/ê²©ë ¤ (ê¸ì •ìœ¼ë¡œ ë´ì•¼ í•¨)
    if current_sentiment != 'ê¸ì •':
        cheer_patterns = [
            r'(?:í™”ì´íŒ…|í™§íŒ…|íŒŒì´íŒ…|í˜ë‚´ì„¸ìš”|í˜ëƒ…ì‹œë‹¤|ì‘ì›í•©ë‹ˆë‹¤)',
            r'(?:í•¨ê»˜|ê°™ì´).*(?:ì´ê²¨|ê·¹ë³µ|í•´ë‚´|í•´ë´)',
        ]
        if has_pattern(text, cheer_patterns) and neg_count <= 1:
            reasons.append("ì‘ì›/ê²©ë ¤ í‘œí˜„")
            return 'ê¸ì •', reasons

    return current_sentiment, []


# ============================================================
# 3. ë©”ì¸ ê²€ì‚¬ ë¡œì§
# ============================================================

def review_item(item):
    """
    ë‹¨ì¼ í•­ëª©ì„ ê²€ì‚¬í•˜ì—¬ ìˆ˜ì •ëœ topic, sentimentì™€ ìˆ˜ì • ì‚¬ìœ ë¥¼ ë°˜í™˜.
    Returns: (new_topic, topic_reason, new_sentiment, sentiment_reason, is_uncertain)
    """
    text = item['text']
    orig_cat = item['original_category']
    current_topic = item['topic']
    current_sentiment = item['sentiment']

    # ì ìˆ˜ ê³„ì‚°
    inv_score = is_primarily_investment(text)
    cr_score = is_primarily_content_reaction(text)
    comm_score = is_primarily_community(text)
    svc_score = is_primarily_service(text)

    new_topic = current_topic
    topic_reason = None
    is_uncertain = False

    # === Topic ìˆ˜ì • ê·œì¹™ ===

    # ê·œì¹™ 1: ì»¤ë®¤ë‹ˆí‹° ì†Œí†µì¸ë° íˆ¬ì í† ë¡ /ì§ˆë¬¸/ë§¤ë§¤ë³´ê³ ê°€ ì£¼ ì˜ë„
    if current_topic == 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ':
        if inv_score >= 5 and inv_score > comm_score + 2:
            new_topic = 'íˆ¬ì ì´ì•¼ê¸°'
            topic_reason = f"ì»¤ë®¤ë‹ˆí‹°â†’íˆ¬ì: íˆ¬ìì ìˆ˜({inv_score})>ì»¤ë®¤ë‹ˆí‹°ì ìˆ˜({comm_score}), íˆ¬ìí† ë¡ /ì§ˆë¬¸ì´ ì£¼ ì˜ë„"
        elif inv_score >= 3 and has_question(text) and has_stock_mention(text):
            new_topic = 'íˆ¬ì ì´ì•¼ê¸°'
            topic_reason = f"ì»¤ë®¤ë‹ˆí‹°â†’íˆ¬ì: ì¢…ëª© ì–¸ê¸‰ + ì§ˆë¬¸ì´ ì£¼ ë‚´ìš©"
        # ì»¤ë®¤ë‹ˆí‹° ì†Œí†µì¸ë° ë§ˆìŠ¤í„° ì½˜í…ì¸  ë°˜ì‘ì´ ì£¼ ì˜ë„
        elif cr_score >= 5 and cr_score > comm_score + 2:
            new_topic = 'ì½˜í…ì¸  ë°˜ì‘'
            topic_reason = f"ì»¤ë®¤ë‹ˆí‹°â†’ì½˜í…ì¸ : ì½˜í…ì¸ ë°˜ì‘ì ìˆ˜({cr_score})>ì»¤ë®¤ë‹ˆí‹°ì ìˆ˜({comm_score})"
        # ì»¤ë®¤ë‹ˆí‹° ì†Œí†µì¸ë° ì„œë¹„ìŠ¤ ì´ìŠˆ (ë³´ë‹¤ ì—„ê²©í•œ ê¸°ì¤€)
        elif svc_score >= 5 and svc_score > comm_score + 2:
            new_topic = 'ì„œë¹„ìŠ¤ ì´ìŠˆ'
            topic_reason = f"ì»¤ë®¤ë‹ˆí‹°â†’ì„œë¹„ìŠ¤: ì„œë¹„ìŠ¤ì ìˆ˜({svc_score})>ì»¤ë®¤ë‹ˆí‹°ì ìˆ˜({comm_score})"

    # ê·œì¹™ 2: ì½˜í…ì¸  ë°˜ì‘ì¸ë° íˆ¬ì í† ë¡ ì´ ì£¼ ë‚´ìš©
    elif current_topic == 'ì½˜í…ì¸  ë°˜ì‘':
        if inv_score >= 6 and cr_score <= 2:
            new_topic = 'íˆ¬ì ì´ì•¼ê¸°'
            topic_reason = f"ì½˜í…ì¸ â†’íˆ¬ì: íˆ¬ìì ìˆ˜({inv_score})ë†’ê³  ì½˜í…ì¸ ë°˜ì‘ì ìˆ˜({cr_score})ë‚®ìŒ"
        # ì½˜í…ì¸  ë°˜ì‘ì¸ë° ì»¤ë®¤ë‹ˆí‹° ì¸ì‚¬ê°€ ì£¼ ì˜ë„
        elif comm_score >= 5 and cr_score <= 2:
            new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
            topic_reason = f"ì½˜í…ì¸ â†’ì»¤ë®¤ë‹ˆí‹°: ì»¤ë®¤ë‹ˆí‹°ì ìˆ˜({comm_score})ë†’ê³  ì½˜í…ì¸ ë°˜ì‘ì ìˆ˜({cr_score})ë‚®ìŒ"
        # ëª…ë³µ, ê±´ê°• ì±™ê¸°ì„¸ìš” ë“±
        elif re.search(r'(?:ëª…ë³µ|ì‚¼ê°€|ì• ë„|ìœ„ë¡œ|ì¶”ëª¨|ì˜ë©´)', text):
            new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
            topic_reason = "ì½˜í…ì¸ â†’ì»¤ë®¤ë‹ˆí‹°: ì¡°ì˜/ìœ„ë¡œ í‘œí˜„ì´ ì£¼ ëª©ì "
        elif re.search(r'(?:ê±´ê°•|ëª¸ì¡°ë¦¬).*(?:ì±™ê¸°|í•˜ì„¸ìš”)', text) and cr_score <= 1:
            new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
            topic_reason = "ì½˜í…ì¸ â†’ì»¤ë®¤ë‹ˆí‹°: ì•ˆë¶€ ì¸ì‚¬ê°€ ì£¼ ëª©ì "
        # ì½˜í…ì¸  ë°˜ì‘ì¸ë° ì„œë¹„ìŠ¤ ì´ìŠˆ (ë³´ë‹¤ ì—„ê²©í•œ ê¸°ì¤€)
        elif svc_score >= 5 and cr_score <= 2:
            new_topic = 'ì„œë¹„ìŠ¤ ì´ìŠˆ'
            topic_reason = f"ì½˜í…ì¸ â†’ì„œë¹„ìŠ¤: ì„œë¹„ìŠ¤ì ìˆ˜({svc_score})ë†’ê³  ì½˜í…ì¸ ë°˜ì‘ì ìˆ˜({cr_score})ë‚®ìŒ"
        # ì½˜í…ì¸  ë°˜ì‘ì¸ë° í•™ìš°/ë™ë£Œì—ê²Œ ê°ì‚¬ (ë§ˆìŠ¤í„°ê°€ ì•„ë‹Œ ë‹¤ë¥¸ íšŒì›ì—ê²Œ)
        elif re.search(r'(?:í•™ìš°|íšŒì›|ë¶„ë“¤?).*(?:ê°ì‚¬|ê³ ë§™|ë•ë¶„)', text) and not has_pattern(text, MASTER_GRATITUDE_PATTERNS):
            if comm_score >= 2:
                new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
                topic_reason = "ì½˜í…ì¸ â†’ì»¤ë®¤ë‹ˆí‹°: í•™ìš°/íšŒì›ì— ëŒ€í•œ ê°ì‚¬ (ë§ˆìŠ¤í„° ì½˜í…ì¸  ë°˜ì‘ ì•„ë‹˜)"

    # ê·œì¹™ 3: íˆ¬ì ì´ì•¼ê¸°ì¸ë° ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ ëª©ì 
    elif current_topic == 'íˆ¬ì ì´ì•¼ê¸°':
        if inv_score <= 2 and comm_score >= 4:
            new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
            topic_reason = f"íˆ¬ìâ†’ì»¤ë®¤ë‹ˆí‹°: íˆ¬ìì ìˆ˜({inv_score})ë‚®ê³  ì»¤ë®¤ë‹ˆí‹°ì ìˆ˜({comm_score})ë†’ìŒ"
        elif inv_score <= 2 and cr_score >= 4:
            new_topic = 'ì½˜í…ì¸  ë°˜ì‘'
            topic_reason = f"íˆ¬ìâ†’ì½˜í…ì¸ : íˆ¬ìì ìˆ˜({inv_score})ë‚®ê³  ì½˜í…ì¸ ë°˜ì‘ì ìˆ˜({cr_score})ë†’ìŒ"
        elif inv_score <= 2 and svc_score >= 5:
            new_topic = 'ì„œë¹„ìŠ¤ ì´ìŠˆ'
            topic_reason = f"íˆ¬ìâ†’ì„œë¹„ìŠ¤: íˆ¬ìì ìˆ˜({inv_score})ë‚®ê³  ì„œë¹„ìŠ¤ì ìˆ˜({svc_score})ë†’ìŒ"
        # ì»¤ë®¤ë‹ˆí‹° ë¶„ìœ„ê¸° ê´€ë ¨ ê¸€ (íˆ¬ìë³´ë‹¤ ì»¤ë®¤ë‹ˆí‹° ì†Œí†µì´ ì£¼)
        elif re.search(r'(?:ë¶„ìœ„ê¸°|ì»¤ë®¤ë‹ˆí‹°|ê²Œì‹œíŒ).*(?:ì‚´ë²Œ|ì•ˆì¢‹|í˜ë“¤|ì”ì“¸)', text) and inv_score <= 3:
            if comm_score >= 2:
                new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
                topic_reason = "íˆ¬ìâ†’ì»¤ë®¤ë‹ˆí‹°: ì»¤ë®¤ë‹ˆí‹° ë¶„ìœ„ê¸°ì— ëŒ€í•œ ì†Œí†µì´ ì£¼ ëª©ì "
        # ë©¤ë²„ì‹­/ì„œë¹„ìŠ¤ ê´€ë ¨ ë¶ˆë§Œì´ ì£¼ ë‚´ìš© (íˆ¬ì ì ìˆ˜ë„ ë†’ì§€ ì•Šì•„ì•¼)
        elif re.search(r'(?:ë©¤ë²„ì‹­|íšŒì›ê´€ë¦¬|ìš´ì˜|ëŒ“ê¸€ê¸°ëŠ¥|ì†Œí†µ).*(?:ë¶ˆë§Œ|ì•ˆë¨|ì•ˆë˜|ì—†|ë¶ˆí¸|ìš”ì²­|í•´ì£¼)', text):
            if svc_score >= 3 and inv_score <= 3:
                new_topic = 'ì„œë¹„ìŠ¤ ì´ìŠˆ'
                topic_reason = "íˆ¬ìâ†’ì„œë¹„ìŠ¤: ì„œë¹„ìŠ¤/ìš´ì˜ ê´€ë ¨ ë¶ˆë§Œì´ ì£¼ ëª©ì "

    # ê·œì¹™ 4: ì„œë¹„ìŠ¤ ì´ìŠˆì¸ë° ë‹¤ë¥¸ ëª©ì 
    elif current_topic == 'ì„œë¹„ìŠ¤ ì´ìŠˆ':
        if svc_score <= 1 and inv_score >= 5:
            new_topic = 'íˆ¬ì ì´ì•¼ê¸°'
            topic_reason = f"ì„œë¹„ìŠ¤â†’íˆ¬ì: ì„œë¹„ìŠ¤ì ìˆ˜({svc_score})ë‚®ê³  íˆ¬ìì ìˆ˜({inv_score})ë†’ìŒ"
        elif svc_score <= 1 and cr_score >= 4:
            new_topic = 'ì½˜í…ì¸  ë°˜ì‘'
            topic_reason = f"ì„œë¹„ìŠ¤â†’ì½˜í…ì¸ : ì„œë¹„ìŠ¤ì ìˆ˜({svc_score})ë‚®ê³  ì½˜í…ì¸ ë°˜ì‘ì ìˆ˜({cr_score})ë†’ìŒ"

    # === ì¶”ê°€ ì •ë°€ ê·œì¹™ ===

    # ì§§ì€ í…ìŠ¤íŠ¸(< 20ì)ì— ëŒ€í•œ íŠ¹ë³„ ê·œì¹™
    if len(text.strip()) < 20:
        stripped = text.strip()
        # ìˆœìˆ˜ ì¸ì‚¬/ì‘ì›
        if re.search(r'^(?:í™”ì´íŒ…|í™§íŒ…|íŒŒì´íŒ…|í˜ë‚´ì„¸ìš”|ì‘ì›í•©ë‹ˆë‹¤|ê°ì‚¬í•©ë‹ˆë‹¤|ê³ ë§™ìŠµë‹ˆë‹¤|ë°˜ê°‘ìŠµë‹ˆë‹¤|ì•ˆë…•í•˜ì„¸ìš”)[!.â™¡â™¥]*\s*$', stripped):
            if current_topic not in ('ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ',):
                new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
                topic_reason = f"{current_topic}â†’ì»¤ë®¤ë‹ˆí‹°: ì§§ì€ ì¸ì‚¬/ê²©ë ¤ ë¬¸êµ¬"
        # ì´ëª¨í‹°ì½˜ë§Œ
        if re.match(r'^[â™¡â™¥â¤ğŸ’šğŸ€ğŸ˜ğŸ˜Šâ˜ºï¸ğŸ‘ğŸ’ªğŸ‰\s]+$', stripped):
            if current_topic != 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ':
                new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
                topic_reason = f"{current_topic}â†’ì»¤ë®¤ë‹ˆí‹°: ì´ëª¨í‹°ì½˜ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸"

    # "ê°ì‚¬í•©ë‹ˆë‹¤ OOë‹˜" (íŠ¹ì • íšŒì›ì—ê²Œ ì§§ì€ ê°ì‚¬) â†’ ì»¤ë®¤ë‹ˆí‹°
    if re.match(r'^(?:ê°ì‚¬í•©ë‹ˆë‹¤|ê°ì‚¬ë“œë¦½ë‹ˆë‹¤|ê³ ë§™ìŠµë‹ˆë‹¤)\s+\S+ë‹˜\s*$', text.strip()):
        if current_topic == 'ì½˜í…ì¸  ë°˜ì‘':
            # ë§ˆìŠ¤í„°ê°€ ì•„ë‹Œ íšŒì›ì—ê²Œ ê°ì‚¬ì¼ ìˆ˜ ìˆìŒ
            new_topic = 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ'
            topic_reason = "ì½˜í…ì¸ â†’ì»¤ë®¤ë‹ˆí‹°: íšŒì›ì— ëŒ€í•œ ì§§ì€ ê°ì‚¬"

    # íˆ¬ì í‚¤ì›Œë“œê°€ ìˆì–´ë„ "ë§ˆìŠ¤í„°ë‹˜ ë•ë¶„ì— íˆ¬ìê°€ ì•ˆì •ì " ë¥˜ëŠ” ì½˜í…ì¸  ë°˜ì‘
    if new_topic == 'íˆ¬ì ì´ì•¼ê¸°' or current_topic == 'íˆ¬ì ì´ì•¼ê¸°':
        gratitude_investment_patterns = [
            r'(?:ìŒ¤|ì„ ìƒë‹˜|êµìˆ˜ë‹˜|ì‘ê°€ë‹˜|ëŒ€í‘œë‹˜|ì›ì¥ë‹˜|ë§ˆìŠ¤í„°ë‹˜).*(?:ë•ë¶„|ê°ì‚¬).*(?:íˆ¬ì|ìˆ˜ìµ|ì•ˆì •|í¸ì•ˆ|ì„±ì¥)',
            r'(?:ë•ë¶„|ê°ì‚¬).*(?:íˆ¬ì|ìˆ˜ìµ|ì•ˆì •|í¸ì•ˆ|ì„±ì¥).*(?:í–ˆ|ë˜ì—ˆ|ë|í•˜ê³ )',
        ]
        if has_pattern(text, gratitude_investment_patterns) and cr_score >= 3:
            if new_topic != 'ì½˜í…ì¸  ë°˜ì‘':
                new_topic = 'ì½˜í…ì¸  ë°˜ì‘'
                topic_reason = "íˆ¬ìâ†’ì½˜í…ì¸ : ë§ˆìŠ¤í„° ë•ë¶„ì˜ íˆ¬ì ì„±ê³¼ ê°ì‚¬ê°€ ì£¼ ëª©ì "

    # === Sentiment ìˆ˜ì • ===
    new_sentiment, sent_reasons = determine_sentiment(text, current_sentiment)
    sentiment_reason = sent_reasons[0] if sent_reasons else None

    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤: ì„œë¹„ìŠ¤ ë¶ˆë§Œì¸ë° ê¸ì •/ì¤‘ë¦½ìœ¼ë¡œ ë˜ì–´ìˆëŠ” ê²½ìš°
    if new_topic == 'ì„œë¹„ìŠ¤ ì´ìŠˆ' and orig_cat in ('ì„œë¹„ìŠ¤ ë¶ˆí¸ì‚¬í•­', 'ì„œë¹„ìŠ¤ í”¼ë“œë°±'):
        if new_sentiment == 'ê¸ì •':
            complaint_check = re.search(r'(?:ë¶ˆí¸|ë¶ˆë§Œ|ì•ˆë¨|ì•ˆë˜|í™˜ë¶ˆ|í•´ì§€|ì˜¤ë¥˜|ë¬¸ì œ)', text)
            if complaint_check:
                new_sentiment = 'ë¶€ì •'
                sentiment_reason = "ì„œë¹„ìŠ¤ ë¶ˆë§Œ ë‚´ìš©ì¸ë° ê¸ì •ìœ¼ë¡œ ë¶„ë¥˜ë¨"

    # ì»¤ë®¤ë‹ˆí‹° ì†Œí†µì—ì„œ ìœ„ë¡œ/ê²©ë ¤ì˜ ë§¥ë½
    if new_topic == 'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ':
        # ìœ„ë¡œ ë§¥ë½ì—ì„œ "í˜ë“¤" ë“±ì´ ìˆì–´ë„ ì „ì²´ í†¤ì´ ê²©ë ¤ë©´ ê¸ì •
        if new_sentiment == 'ë¶€ì •' and has_pattern(text, [
            r'(?:í˜ë“¤|ì–´ë µ|ê±±ì •).*(?:í™”ì´íŒ…|í™§íŒ…|íŒŒì´íŒ…|í˜ë‚´|í•¨ê»˜|ì‘ì›)',
            r'(?:í™”ì´íŒ…|í™§íŒ…|íŒŒì´íŒ…|í˜ë‚´|í•¨ê»˜|ì‘ì›).*(?:í˜ë“¤|ì–´ë µ|ê±±ì •)',
        ]):
            pos_c = count_keywords(text, POSITIVE_KEYWORDS)
            neg_c = count_keywords(text, NEGATIVE_KEYWORDS)
            if pos_c >= neg_c:
                new_sentiment = 'ê¸ì •'
                sentiment_reason = "ê²©ë ¤/ìœ„ë¡œ ë§¥ë½ì—ì„œ ë¶€ì • í‚¤ì›Œë“œ ì‚¬ìš© (ì „ì²´ í†¤ì€ ê¸ì •)"

    # === ë¶ˆí™•ì‹¤ íŒì • ===
    # ì ìˆ˜ ì°¨ì´ê°€ ì‘ì€ ê²½ìš° (ê²½ê³„ì„ )
    scores = {
        'íˆ¬ì ì´ì•¼ê¸°': inv_score,
        'ì½˜í…ì¸  ë°˜ì‘': cr_score,
        'ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ': comm_score,
        'ì„œë¹„ìŠ¤ ì´ìŠˆ': svc_score,
    }
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)

    if len(sorted_scores) >= 2:
        top_topic, top_score = sorted_scores[0]
        second_topic, second_score = sorted_scores[1]
        if top_score > 0 and second_score > 0 and (top_score - second_score) <= 2:
            is_uncertain = True

    # topicì´ ìˆ˜ì •ë˜ì—ˆê³  ì ìˆ˜ ì°¨ì´ê°€ í¬ì§€ ì•Šì€ ê²½ìš°ë„ ë¶ˆí™•ì‹¤
    if topic_reason and new_topic != current_topic:
        assigned_score = scores.get(new_topic, 0)
        original_score = scores.get(current_topic, 0)
        if assigned_score - original_score <= 3:
            is_uncertain = True

    return new_topic, topic_reason, new_sentiment, sentiment_reason, is_uncertain


# ============================================================
# 4. ì‹¤í–‰
# ============================================================

def main():
    # ë°ì´í„° ë¡œë“œ
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"ì „ìˆ˜ê²€ì‚¬ ì‹œì‘: {len(data)}ê±´")
    print("=" * 70)

    # ìˆ˜ì • ì¶”ì 
    topic_changes = []
    sentiment_changes = []
    uncertain_items = []

    reviewed_data = []

    for idx, item in enumerate(data):
        new_topic, topic_reason, new_sentiment, sentiment_reason, is_uncertain = review_item(item)

        reviewed_item = {
            'text': item['text'],
            'original_category': item['original_category'],
            'topic': new_topic,
            'sentiment': new_sentiment,
        }
        reviewed_data.append(reviewed_item)

        # Topic ë³€ê²½ ê¸°ë¡
        if new_topic != item['topic']:
            change = {
                'index': idx,
                'text': item['text'][:80],
                'original_topic': item['topic'],
                'new_topic': new_topic,
                'reason': topic_reason,
            }
            topic_changes.append(change)

        # Sentiment ë³€ê²½ ê¸°ë¡
        if new_sentiment != item['sentiment']:
            change = {
                'index': idx,
                'text': item['text'][:80],
                'original_sentiment': item['sentiment'],
                'new_sentiment': new_sentiment,
                'reason': sentiment_reason,
            }
            sentiment_changes.append(change)

        # ë¶ˆí™•ì‹¤ í•­ëª© ê¸°ë¡
        if is_uncertain:
            uncertain_item = {
                'index': idx,
                'text': item['text'][:200],
                'original_category': item['original_category'],
                'original_topic': item['topic'],
                'assigned_topic': new_topic,
                'original_sentiment': item['sentiment'],
                'assigned_sentiment': new_sentiment,
                'topic_reason': topic_reason,
                'sentiment_reason': sentiment_reason,
            }
            uncertain_items.append(uncertain_item)

    # === ì €ì¥ ===
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(reviewed_data, f, ensure_ascii=False, indent=2)
    print(f"\nìˆ˜ì •ëœ ë°ì´í„° ì €ì¥: {OUTPUT_FILE}")

    with open(UNCERTAIN_FILE, 'w', encoding='utf-8') as f:
        json.dump(uncertain_items, f, ensure_ascii=False, indent=2)
    print(f"ë¶ˆí™•ì‹¤ í•­ëª© ì €ì¥: {UNCERTAIN_FILE} ({len(uncertain_items)}ê±´)")

    # === í†µê³„ ì¶œë ¥ ===
    print("\n" + "=" * 70)
    print("[ Topic ìˆ˜ì • í†µê³„ ]")
    print(f"ì´ ìˆ˜ì • ê±´ìˆ˜: {len(topic_changes)}")

    # reasonë³„ ì§‘ê³„
    topic_reason_counter = Counter()
    for c in topic_changes:
        # ê°„ëµí™”ëœ reason í‚¤ ì¶”ì¶œ
        reason = c['reason']
        if 'â†’íˆ¬ì' in reason:
            key = f"{c['original_topic']} â†’ íˆ¬ì ì´ì•¼ê¸°"
        elif 'â†’ì½˜í…ì¸ ' in reason:
            key = f"{c['original_topic']} â†’ ì½˜í…ì¸  ë°˜ì‘"
        elif 'â†’ì»¤ë®¤ë‹ˆí‹°' in reason:
            key = f"{c['original_topic']} â†’ ì»¤ë®¤ë‹ˆí‹° ì†Œí†µ"
        elif 'â†’ì„œë¹„ìŠ¤' in reason:
            key = f"{c['original_topic']} â†’ ì„œë¹„ìŠ¤ ì´ìŠˆ"
        else:
            key = reason
        topic_reason_counter[key] += 1

    for reason, count in topic_reason_counter.most_common():
        print(f"  {reason}: {count}ê±´")

    print(f"\n[ Sentiment ìˆ˜ì • í†µê³„ ]")
    print(f"ì´ ìˆ˜ì • ê±´ìˆ˜: {len(sentiment_changes)}")

    sent_reason_counter = Counter()
    for c in sentiment_changes:
        reason_key = c.get('reason', 'ê¸°íƒ€')
        if reason_key:
            sent_reason_counter[reason_key] += 1

    for reason, count in sent_reason_counter.most_common():
        print(f"  {reason}: {count}ê±´")

    # ì „í™˜ ë°©í–¥ë³„ ì§‘ê³„
    sent_direction_counter = Counter()
    for c in sentiment_changes:
        key = f"{c['original_sentiment']} â†’ {c['new_sentiment']}"
        sent_direction_counter[key] += 1

    print(f"\n  [ë°©í–¥ë³„]")
    for direction, count in sent_direction_counter.most_common():
        print(f"    {direction}: {count}ê±´")

    # === ìˆ˜ì • ì „/í›„ ë¶„í¬ ë¹„êµ ===
    print(f"\n{'=' * 70}")
    print("[ ìˆ˜ì • ì „/í›„ ë¶„í¬ ë¹„êµ ]")

    # Topic ë¶„í¬
    before_topics = Counter(d['topic'] for d in data)
    after_topics = Counter(d['topic'] for d in reviewed_data)

    print(f"\n  Topic ë¶„í¬:")
    print(f"  {'í† í”½':<15} {'ìˆ˜ì • ì „':>8} {'ìˆ˜ì • í›„':>8} {'ë³€í™”':>8}")
    print(f"  {'-'*43}")
    all_topics = sorted(set(list(before_topics.keys()) + list(after_topics.keys())))
    for t in all_topics:
        before = before_topics.get(t, 0)
        after = after_topics.get(t, 0)
        diff = after - before
        sign = '+' if diff > 0 else ''
        print(f"  {t:<15} {before:>8} {after:>8} {sign}{diff:>7}")

    # Sentiment ë¶„í¬
    before_sents = Counter(d['sentiment'] for d in data)
    after_sents = Counter(d['sentiment'] for d in reviewed_data)

    print(f"\n  Sentiment ë¶„í¬:")
    print(f"  {'ê°ì„±':<10} {'ìˆ˜ì • ì „':>8} {'ìˆ˜ì • í›„':>8} {'ë³€í™”':>8}")
    print(f"  {'-'*38}")
    all_sents = sorted(set(list(before_sents.keys()) + list(after_sents.keys())))
    for s in all_sents:
        before = before_sents.get(s, 0)
        after = after_sents.get(s, 0)
        diff = after - before
        sign = '+' if diff > 0 else ''
        print(f"  {s:<10} {before:>8} {after:>8} {sign}{diff:>7}")

    # Cross-tab (ìˆ˜ì • í›„)
    print(f"\n  Topic x Sentiment (ìˆ˜ì • í›„):")
    for t in all_topics:
        for s in all_sents:
            cnt = sum(1 for d in reviewed_data if d['topic'] == t and d['sentiment'] == s)
            if cnt:
                print(f"    {t} x {s}: {cnt}")

    # === ìˆ˜ì • ìƒ˜í”Œ ì¶œë ¥ ===
    print(f"\n{'=' * 70}")
    print("[ Topic ìˆ˜ì • ìƒ˜í”Œ (ìµœëŒ€ 30ê±´) ]")
    for i, c in enumerate(topic_changes[:30]):
        print(f"\n  [{i+1}] idx={c['index']}")
        print(f"      í…ìŠ¤íŠ¸: {c['text']}...")
        print(f"      ë³€ê²½: {c['original_topic']} â†’ {c['new_topic']}")
        print(f"      ì‚¬ìœ : {c['reason']}")

    if len(topic_changes) > 30:
        print(f"\n  ... ì™¸ {len(topic_changes) - 30}ê±´ ì¶”ê°€")

    print(f"\n{'=' * 70}")
    print("[ Sentiment ìˆ˜ì • ìƒ˜í”Œ (ìµœëŒ€ 30ê±´) ]")
    for i, c in enumerate(sentiment_changes[:30]):
        print(f"\n  [{i+1}] idx={c['index']}")
        print(f"      í…ìŠ¤íŠ¸: {c['text']}...")
        print(f"      ë³€ê²½: {c['original_sentiment']} â†’ {c['new_sentiment']}")
        print(f"      ì‚¬ìœ : {c['reason']}")

    if len(sentiment_changes) > 30:
        print(f"\n  ... ì™¸ {len(sentiment_changes) - 30}ê±´ ì¶”ê°€")

    print(f"\n{'=' * 70}")
    print(f"[ ë¶ˆí™•ì‹¤ í•­ëª©: {len(uncertain_items)}ê±´ ]")
    for i, u in enumerate(uncertain_items[:20]):
        print(f"\n  [{i+1}] idx={u['index']}")
        print(f"      í…ìŠ¤íŠ¸: {u['text'][:80]}...")
        print(f"      Topic: {u['original_topic']} â†’ {u['assigned_topic']}")
        print(f"      Sentiment: {u['original_sentiment']} â†’ {u['assigned_sentiment']}")
        if u['topic_reason']:
            print(f"      Topic ì‚¬ìœ : {u['topic_reason']}")
        if u['sentiment_reason']:
            print(f"      Sentiment ì‚¬ìœ : {u['sentiment_reason']}")

    if len(uncertain_items) > 20:
        print(f"\n  ... ì™¸ {len(uncertain_items) - 20}ê±´ ì¶”ê°€ (uncertain_items.json ì°¸ì¡°)")

    print(f"\n{'=' * 70}")
    print("ì „ìˆ˜ê²€ì‚¬ ì™„ë£Œ.")


if __name__ == '__main__':
    main()
